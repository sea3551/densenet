import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms, datasets
from torchvision.models import DenseNet161_Weights
from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score
import numpy as np
import os
from tqdm import tqdm
from torchinfo import summary  # ëª¨ë¸ êµ¬ì¡° ì¶œë ¥ìš©

# âœ… GPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ”¹ Using device: {device}")

# âœ… ë°ì´í„°ì…‹ ë¡œë“œ ë° ë³€í™˜ ì •ì˜
data_dir = "spectrogram_images/day1"
transform = transforms.Compose([transforms.ToTensor()])
dataset = datasets.ImageFolder(root=data_dir, transform=transform)

# âœ… í´ë˜ìŠ¤ë³„ 8:2 ë°ì´í„° ë¶„í•  í•¨ìˆ˜
def stratified_split(dataset, train_ratio=0.8):
    labels = [label for _, label in dataset.samples]
    sss = StratifiedShuffleSplit(n_splits=1, test_size=1 - train_ratio, random_state=42)
    train_idx, test_idx = next(sss.split(np.zeros(len(labels)), labels))
    return Subset(dataset, train_idx), Subset(dataset, test_idx)

# âœ… ë°ì´í„°ì…‹ ë¶„í• 
train_dataset, test_dataset = stratified_split(dataset, train_ratio=0.8)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)

print(f"ğŸ”¹ í´ë˜ìŠ¤ ëª©ë¡: {dataset.classes}")

# âœ… DenseNet ëª¨ë¸ ì •ì˜
def build_model(num_classes):
    model = models.densenet161(weights=DenseNet161_Weights.IMAGENET1K_V1)
    model.classifier = nn.Linear(model.classifier.in_features, num_classes)
    return model.to(device)

model = build_model(len(dataset.classes))

# âœ… ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
summary(model, input_size=(1, dataset[0][0].shape[0], 400, 400), device=device)

# âœ… ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
num_epochs = 10

# âœ… í›ˆë ¨ í•¨ìˆ˜
def train_model(model, train_loader, criterion, optimizer, num_epochs):
    best_acc = 0.0  # ìµœê³  ì„±ëŠ¥ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜
    
    print(f"\nğŸ”¹ Training Start | Epochs: {num_epochs}, Batch Size: {train_loader.batch_size}, Device: {device}")
    
    for epoch in range(num_epochs):
        model.train()
        running_loss, correct, total = 0.0, 0, 0

        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", leave=False)
        for images, labels in progress_bar:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            correct += (outputs.argmax(1) == labels).sum().item()
            total += labels.size(0)

            progress_bar.set_postfix(loss=running_loss / (total / 4), acc=correct / total)

        epoch_acc = correct / total
        print(f"Epoch {epoch+1}/{num_epochs} âœ… Loss: {running_loss/len(train_loader):.4f}, Accuracy: {epoch_acc:.4f}")

        # âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if epoch_acc > best_acc:
            best_acc = epoch_acc
            torch.save(model.state_dict(), "best_model.pth")
            print(f"âœ… Best Model Saved with Accuracy: {best_acc:.4f}")

# âœ… Rank-K Accuracy ê³„ì‚° í•¨ìˆ˜
def rank_k_accuracy(y_true, y_scores, k=5):
    """
    Rank-K Accuracyë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    :param y_true: ì‹¤ì œ ì •ë‹µ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
    :param y_scores: ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥  (Softmax ê°’)
    :param k: Top-K ë²”ìœ„ (ê¸°ë³¸ê°’: 5)
    :return: Rank-K ì •í™•ë„
    """
    correct = 0
    for i in range(len(y_true)):
        top_k_predictions = np.argsort(y_scores[i])[-k:]  # ìƒìœ„ Kê°œ ì˜ˆì¸¡ê°’ ì¸ë±ìŠ¤
        if y_true[i] in top_k_predictions:
            correct += 1
    return correct / len(y_true)

# âœ… ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ (Confusion Matrix + Rank-K Accuracy ì¶”ê°€)
def evaluate_model(model, test_loader):
    model.eval()
    y_true, y_pred, y_scores = [], [], []

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(outputs.argmax(1).cpu().numpy())
            y_scores.extend(outputs.cpu().numpy())  # í™•ë¥  ê°’ ì €ì¥

    # âœ… Confusion Matrix ê³„ì‚°
    cm = confusion_matrix(y_true, y_pred)
    class_labels = dataset.classes

    # âœ… Confusion Matrix ì¶œë ¥ (í„°ë¯¸ë„ìš©)
    print("\nğŸ”¹ Confusion Matrix:")
    print("    " + "  ".join(f"{label[:4]:>4}" for label in class_labels))  # í´ë˜ìŠ¤ ë¼ë²¨ ì¶œë ¥
    for i, row in enumerate(cm):
        print(f"{class_labels[i][:4]:>4} " + "  ".join(f"{val:>4}" for val in row))

    # âœ… Rank-K Accuracy ê³„ì‚°
    rank1_acc = rank_k_accuracy(y_true, y_scores, k=1)
    rank3_acc = rank_k_accuracy(y_true, y_scores, k=3)
    rank5_acc = rank_k_accuracy(y_true, y_scores, k=5)

    # âœ… í‰ê°€ ì§€í‘œ ì¶œë ¥
    accuracy = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average="weighted")
    print(f"\nğŸ”¹ Test Accuracy: {accuracy:.4f}")
    print(f"ğŸ”¹ F1 Score: {f1:.4f}")
    print(f"ğŸ”¹ Rank-1 Accuracy: {rank1_acc:.4f}")
    print(f"ğŸ”¹ Rank-3 Accuracy: {rank3_acc:.4f}")
    print(f"ğŸ”¹ Rank-5 Accuracy: {rank5_acc:.4f}")
    print("\nğŸ”¹ Classification Report:\n", classification_report(y_true, y_pred, target_names=class_labels))

# âœ… ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
train_model(model, train_loader, criterion, optimizer, num_epochs)

# âœ… ëª¨ë¸ í‰ê°€ ì‹¤í–‰
evaluate_model(model, test_loader)
