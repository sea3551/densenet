import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms, datasets
from torchvision.models import DenseNet161_Weights
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
from tqdm import tqdm  # ì§„í–‰ë¥  ë°” ì¶”ê°€
from torchinfo import summary  # ëª¨ë¸ ë ˆì´ì–´ ì¶œë ¥ìš©

if __name__ == '__main__':
    # âœ… GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”¹ Using device: {device}")

    # âœ… ë°ì´í„° ë¡œë“œ
    data_dir = "spectrogram_images/day1"
    transform = transforms.Compose([transforms.ToTensor()])

    dataset = datasets.ImageFolder(root=data_dir, transform=transform)
    train_size = int(0.8 * len(dataset))
    test_size = len(dataset) - train_size
    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)

    print(f"ğŸ”¹ í´ë˜ìŠ¤ ëª©ë¡: {dataset.classes}")

    # âœ… ëª¨ë¸ ë¡œë“œ ë° ìˆ˜ì •
    model = models.densenet161(weights=DenseNet161_Weights.IMAGENET1K_V1)
    model.classifier = nn.Linear(model.classifier.in_features, len(dataset.classes))
    model.to(device)

    # âœ… ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
    summary(model, input_size=(1, dataset[0][0].shape[0], 400, 400), device=device)

    # âœ… í•™ìŠµ ì„¤ì •
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    num_epochs = 10

    # âœ… ëª¨ë¸ í•™ìŠµ ì‹œì‘
    print(f"\nğŸ”¹ Training Start | Epochs: {num_epochs}, Batch Size: {train_loader.batch_size}, Device: {device}")

    for epoch in range(num_epochs):
        model.train()
        running_loss, correct, total = 0.0, 0, 0

        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", leave=False)
        for images, labels in progress_bar:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            correct += (outputs.argmax(1) == labels).sum().item()
            total += labels.size(0)

            progress_bar.set_postfix(loss=running_loss / (total / 4), acc=correct / total)

        print(f"Epoch {epoch+1}/{num_epochs} âœ… Loss: {running_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}")

    # âœ… ì„±ëŠ¥ í‰ê°€
    model.eval()
    y_true, y_pred = [], []

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(model(images).argmax(1).cpu().numpy())

    # âœ… Confusion Matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt="d", cmap="Blues",
                xticklabels=dataset.classes, yticklabels=dataset.classes)
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.show()

    # âœ… í‰ê°€ ì§€í‘œ ì¶œë ¥
    print(f"\nğŸ”¹ Test Accuracy: {accuracy_score(y_true, y_pred):.4f}")
    print(f"ğŸ”¹ F1 Score: {f1_score(y_true, y_pred, average='weighted'):.4f}")
    print("\nğŸ”¹ Classification Report:\n", classification_report(y_true, y_pred, target_names=dataset.classes))
